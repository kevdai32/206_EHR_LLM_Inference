{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9caeff-54e0-43f8-8ef1-472c61ed272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/llm_tools1/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c199a3-b4d4-4c97-94b9-0fce0117c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1462f1-838b-4fbf-96c9-9069bb774d4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (9999) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "path_to_model = '/home/ubuntu/Final_project/openhermes-2.5-mistral-7b.Q2_K.gguf'\n",
    "#path_to_model = '/mnt/efs/home/ubuntu/Final_project/medgemma-27b-it-Q5_K_M.gguf'\n",
    "llm = Llama(model_path = path_to_model, \n",
    "            n_ctx = 9999, \n",
    "            max_new_tokens = 2048, \n",
    "            temperature = 0.1, \n",
    "            cache = False, \n",
    "            verbose = False,\n",
    "            n_gpu_layers = -1,\n",
    "            n_threads = 6,\n",
    "            chat_format = 'chatml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1374fc1e-a928-4968-8e8d-b43fd394c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_format = {\n",
    "#     \"type\": \"json_object\",\n",
    "#     \"schema\": {\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\n",
    "#             \"imatinib_mentioned\": {\n",
    "#                 \"type\": \"boolean\",\n",
    "#                 \"description\": \"True if the drug imatinib is mentioned in the note\"\n",
    "#             },\n",
    "#             \"cml_diagnosed\": {\n",
    "#                 \"type\": \"boolean\",\n",
    "#                 \"description\": \"True if chronic myeloid leukemia is diagnosed\"\n",
    "#             },\n",
    "#             \"cml_in_regression\": {\n",
    "#                 \"type\": \"boolean\",\n",
    "#                 \"description\": \"True if chronic myeloid leukemia is mentioned as being in regression\"\n",
    "#             }\n",
    "#         },\n",
    "#         \"required\": [\"imatinib_mentioned\", \"cml_diagnosed\", \"cml_in_regression\"]\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3851810a-a1f5-4554-9b5d-c5a51ee900d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = \"\"\"\n",
    "# You are a strict JSON generator. Only output JSON that matches the schema below.\n",
    "# Do not include any extra text, commentary, or explanations.\n",
    "\n",
    "# Schema:\n",
    "# - imatinib_mentioned: true if the drug imatinib is mentioned in the note, otherwise false\n",
    "# - cml_diagnosed: true if chronic myeloid leukemia is diagnosed, otherwise false\n",
    "# - cml_in_regression: true if chronic myeloid leukemia is mentioned as being in regression, otherwise false\n",
    "\n",
    "# Rules:\n",
    "# 1. Only mark a field as true if the note clearly indicates it.\n",
    "# 2. If the note does not explicitly mention a field, mark it false.\n",
    "# 3. The output must always be valid JSON with all three fields present.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870d9d3-eeb6-466b-9b22-3766fb5074f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e57f9a-642c-48e7-b52a-dfe51738e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_format = {\n",
    "    \"type\": \"json_object\",\n",
    "    \"schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"imatinib_mentioned\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"True if the drug imatinib is mentioned in the note\"\n",
    "            },\n",
    "            \"related_drugs_mentioned\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"True if drugs related to imatinib (e.g., dasatinib, nilotinib, bosutinib) are mentioned\"\n",
    "            },\n",
    "            \"cml_diagnosed\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"True if chronic myeloid leukemia is diagnosed\"\n",
    "            },\n",
    "            \"cml_in_regression\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"True if chronic myeloid leukemia is mentioned as being in regression\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"imatinib_mentioned\", \"related_drugs_mentioned\", \"cml_diagnosed\", \"cml_in_regression\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a19707-29ab-4bfb-9262-af60b2a4339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a strict JSON generator. Only output JSON that matches the schema below.\n",
    "Do not include any extra text, commentary, or explanations.\n",
    "\n",
    "Schema:\n",
    "- imatinib_mentioned: true if the drug imatinib is mentioned in the note, otherwise false\n",
    "- related_drugs_mentioned: true if drugs related to imatinib (e.g., dasatinib, nilotinib, bosutinib) are mentioned, otherwise false\n",
    "- cml_diagnosed: true if chronic myeloid leukemia is diagnosed, otherwise false\n",
    "- cml_in_regression: true if chronic myeloid leukemia is mentioned as being in regression, otherwise false\n",
    "\n",
    "Rules:\n",
    "1. Only mark a field as true if the note clearly indicates it.\n",
    "2. If the note does not explicitly mention a field, mark it false.\n",
    "3. The output must always be valid JSON with all four fields present.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "137c264c-b283-48d9-985f-1cf6624489e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       |                           ***** Data extract...\n",
       "1       |                           ***** Data extract...\n",
       "2       |                           ***** Data extract...\n",
       "3         Subjective:     The patient returns for foll...\n",
       "4       REPORT:          VISIT SUMMARY - HEMATOLOGY/ON...\n",
       "                              ...                        \n",
       "1757    Received admissions/referral packet from *****...\n",
       "1758                                                   \\n\n",
       "1759    Today I ***** ***** *****, ***** ***** y.o. fe...\n",
       "1760    Formatting of this note is different from the ...\n",
       "1761    Formatting of this note is different from the ...\n",
       "Name: note_text, Length: 1762, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_notes = clinical_notes_all_path = \"latest_notes.parquet\"\n",
    "# clinical_notes_all = pd.read_parquet(clinical_notes_all_path, engine='pyarrow')\n",
    "# clinical_notes_all.columns\n",
    "# clinical_notes_all['note_text']\n",
    "# first_300 = clinical_notes_all['note_text']\n",
    "# first_300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec22713-b042-4973-a448-67014577c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('latest_notes.parquet')\n",
    "#df = df.iloc[:40]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "911eade5-415b-46d1-b141-b0e9369c8dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 / 40 notes\n",
      "Processed 20 / 40 notes\n",
      "Processed 30 / 40 notes\n",
      "Processed 40 / 40 notes\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "\n",
    "# sample_notes = df['note_text'].values\n",
    "# labelled_notes = []\n",
    "\n",
    "# for i, note in enumerate(sample_notes, 1):\n",
    "#     if len(note) > 11000:\n",
    "#         note = note[:11000]\n",
    "\n",
    "#     structured_output = llm.create_chat_completion(\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": system_prompt},\n",
    "#             {\"role\": \"user\", \"content\": note}\n",
    "#         ],\n",
    "#         response_format=label_format,\n",
    "#         temperature=0,\n",
    "#     )\n",
    "\n",
    "#     raw_content = structured_output['choices'][0]['message']['content']\n",
    "\n",
    "#     # extract first {...} block\n",
    "#     match = re.search(r\"\\{.*\\}\", raw_content, re.DOTALL)\n",
    "#     if match:\n",
    "#         label = json.loads(match.group())\n",
    "#     else:\n",
    "#         # fallback if JSON not found\n",
    "#         label = {\n",
    "#             \"imatinib_mentioned\": False,\n",
    "#             \"cml_diagnosed\": False,\n",
    "#             \"cml_in_regression\": False\n",
    "#         }\n",
    "\n",
    "#     labelled_notes.append({\n",
    "#         \"original_note\": note,\n",
    "#         \"imatinib_mentioned\": label[\"imatinib_mentioned\"],\n",
    "#         \"cml_diagnosed\": label[\"cml_diagnosed\"],\n",
    "#         \"cml_in_regression\": label[\"cml_in_regression\"],\n",
    "#     })\n",
    "\n",
    "#     if i % 10 == 0:\n",
    "#         print(f\"Processed {i} / {len(sample_notes)} notes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0151d348-e846-419e-ad59-48ea53761214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"open_hermes_test.json\", \"w\") as f:\n",
    "#     json.dump(labelled_notes, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1eea5-e1f3-4c30-b894-2a9e426407c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2492c2c2-1202-47dd-969d-c9b9ab5c30c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 / 1762 notes\n",
      "Processed 20 / 1762 notes\n",
      "Processed 30 / 1762 notes\n",
      "Processed 40 / 1762 notes\n",
      "Processed 50 / 1762 notes\n",
      "Processed 60 / 1762 notes\n",
      "Processed 70 / 1762 notes\n",
      "Processed 80 / 1762 notes\n",
      "Processed 90 / 1762 notes\n",
      "Processed 100 / 1762 notes\n",
      "Processed 110 / 1762 notes\n",
      "Processed 120 / 1762 notes\n",
      "Processed 130 / 1762 notes\n",
      "Processed 140 / 1762 notes\n",
      "Processed 150 / 1762 notes\n",
      "Processed 160 / 1762 notes\n",
      "Processed 170 / 1762 notes\n",
      "Processed 180 / 1762 notes\n",
      "Processed 190 / 1762 notes\n",
      "Processed 200 / 1762 notes\n",
      "Processed 210 / 1762 notes\n",
      "Processed 220 / 1762 notes\n",
      "Processed 230 / 1762 notes\n",
      "Processed 240 / 1762 notes\n",
      "Processed 250 / 1762 notes\n",
      "Processed 260 / 1762 notes\n",
      "Processed 270 / 1762 notes\n",
      "Processed 280 / 1762 notes\n",
      "Processed 290 / 1762 notes\n",
      "Processed 300 / 1762 notes\n",
      "Processed 310 / 1762 notes\n",
      "Processed 320 / 1762 notes\n",
      "Processed 330 / 1762 notes\n",
      "Processed 340 / 1762 notes\n",
      "Processed 350 / 1762 notes\n",
      "Processed 360 / 1762 notes\n",
      "Processed 370 / 1762 notes\n",
      "Processed 380 / 1762 notes\n",
      "Processed 390 / 1762 notes\n",
      "Processed 400 / 1762 notes\n",
      "Processed 410 / 1762 notes\n",
      "Processed 420 / 1762 notes\n",
      "Processed 430 / 1762 notes\n",
      "Processed 440 / 1762 notes\n",
      "Processed 450 / 1762 notes\n",
      "Processed 460 / 1762 notes\n",
      "Processed 470 / 1762 notes\n",
      "Processed 480 / 1762 notes\n",
      "Processed 490 / 1762 notes\n",
      "Processed 500 / 1762 notes\n",
      "Processed 510 / 1762 notes\n",
      "Processed 520 / 1762 notes\n",
      "Processed 530 / 1762 notes\n",
      "Processed 540 / 1762 notes\n",
      "Processed 550 / 1762 notes\n",
      "Processed 560 / 1762 notes\n",
      "Processed 570 / 1762 notes\n",
      "Processed 580 / 1762 notes\n",
      "Processed 590 / 1762 notes\n",
      "Processed 600 / 1762 notes\n",
      "Processed 610 / 1762 notes\n",
      "Processed 620 / 1762 notes\n",
      "Processed 630 / 1762 notes\n",
      "Processed 640 / 1762 notes\n",
      "Processed 650 / 1762 notes\n",
      "Processed 660 / 1762 notes\n",
      "Processed 670 / 1762 notes\n",
      "Processed 680 / 1762 notes\n",
      "Processed 690 / 1762 notes\n",
      "Processed 700 / 1762 notes\n",
      "Processed 710 / 1762 notes\n",
      "Processed 720 / 1762 notes\n",
      "Processed 730 / 1762 notes\n",
      "Processed 740 / 1762 notes\n",
      "Processed 750 / 1762 notes\n",
      "Processed 760 / 1762 notes\n",
      "Processed 770 / 1762 notes\n",
      "Processed 780 / 1762 notes\n",
      "Processed 790 / 1762 notes\n",
      "Processed 800 / 1762 notes\n",
      "Processed 810 / 1762 notes\n",
      "Processed 820 / 1762 notes\n",
      "Processed 830 / 1762 notes\n",
      "Processed 840 / 1762 notes\n",
      "Processed 850 / 1762 notes\n",
      "Processed 860 / 1762 notes\n",
      "Processed 870 / 1762 notes\n",
      "Processed 880 / 1762 notes\n",
      "Processed 890 / 1762 notes\n",
      "Processed 900 / 1762 notes\n",
      "Processed 910 / 1762 notes\n",
      "Processed 920 / 1762 notes\n",
      "Processed 930 / 1762 notes\n",
      "Processed 940 / 1762 notes\n",
      "Processed 950 / 1762 notes\n",
      "Processed 960 / 1762 notes\n",
      "Processed 970 / 1762 notes\n",
      "Processed 980 / 1762 notes\n",
      "Processed 990 / 1762 notes\n",
      "Processed 1000 / 1762 notes\n",
      "Processed 1010 / 1762 notes\n",
      "Processed 1020 / 1762 notes\n",
      "Processed 1030 / 1762 notes\n",
      "Processed 1040 / 1762 notes\n",
      "Processed 1050 / 1762 notes\n",
      "Processed 1060 / 1762 notes\n",
      "Processed 1070 / 1762 notes\n",
      "Processed 1080 / 1762 notes\n",
      "Processed 1090 / 1762 notes\n",
      "Processed 1100 / 1762 notes\n",
      "Processed 1110 / 1762 notes\n",
      "Processed 1120 / 1762 notes\n",
      "Processed 1130 / 1762 notes\n",
      "Processed 1140 / 1762 notes\n",
      "Processed 1150 / 1762 notes\n",
      "Processed 1160 / 1762 notes\n",
      "Processed 1170 / 1762 notes\n",
      "Processed 1180 / 1762 notes\n",
      "Processed 1190 / 1762 notes\n",
      "Processed 1200 / 1762 notes\n",
      "Processed 1210 / 1762 notes\n",
      "Processed 1220 / 1762 notes\n",
      "Processed 1230 / 1762 notes\n",
      "Processed 1240 / 1762 notes\n",
      "Processed 1250 / 1762 notes\n",
      "Processed 1260 / 1762 notes\n",
      "Processed 1270 / 1762 notes\n",
      "Processed 1280 / 1762 notes\n",
      "Processed 1290 / 1762 notes\n",
      "Processed 1300 / 1762 notes\n",
      "Processed 1310 / 1762 notes\n",
      "Processed 1320 / 1762 notes\n",
      "Processed 1330 / 1762 notes\n",
      "Processed 1340 / 1762 notes\n",
      "Processed 1350 / 1762 notes\n",
      "Processed 1360 / 1762 notes\n",
      "Processed 1370 / 1762 notes\n",
      "Processed 1380 / 1762 notes\n",
      "Processed 1390 / 1762 notes\n",
      "Processed 1400 / 1762 notes\n",
      "Processed 1410 / 1762 notes\n",
      "Processed 1420 / 1762 notes\n",
      "Processed 1430 / 1762 notes\n",
      "Processed 1440 / 1762 notes\n",
      "Processed 1450 / 1762 notes\n",
      "Processed 1460 / 1762 notes\n",
      "Processed 1470 / 1762 notes\n",
      "Processed 1480 / 1762 notes\n",
      "Processed 1490 / 1762 notes\n",
      "Processed 1500 / 1762 notes\n",
      "Processed 1510 / 1762 notes\n",
      "Processed 1520 / 1762 notes\n",
      "Processed 1530 / 1762 notes\n",
      "Processed 1540 / 1762 notes\n",
      "Processed 1550 / 1762 notes\n",
      "Processed 1560 / 1762 notes\n",
      "Processed 1570 / 1762 notes\n",
      "Processed 1580 / 1762 notes\n",
      "Processed 1590 / 1762 notes\n",
      "Processed 1600 / 1762 notes\n",
      "Processed 1610 / 1762 notes\n",
      "Processed 1620 / 1762 notes\n",
      "Processed 1630 / 1762 notes\n",
      "Processed 1640 / 1762 notes\n",
      "Processed 1650 / 1762 notes\n",
      "Processed 1660 / 1762 notes\n",
      "Processed 1670 / 1762 notes\n",
      "Processed 1680 / 1762 notes\n",
      "Processed 1690 / 1762 notes\n",
      "Processed 1700 / 1762 notes\n",
      "Processed 1710 / 1762 notes\n",
      "Processed 1720 / 1762 notes\n",
      "Processed 1730 / 1762 notes\n",
      "Processed 1740 / 1762 notes\n",
      "Processed 1750 / 1762 notes\n",
      "Processed 1760 / 1762 notes\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "import re\n",
    "\n",
    "sample_notes = df['note_text'].values\n",
    "labelled_notes = []\n",
    "\n",
    "for i, note in enumerate(sample_notes, 1):\n",
    "    # truncate long notes\n",
    "    if len(note) > 11000:\n",
    "        note = note[:11000]\n",
    "\n",
    "    structured_output = llm.create_chat_completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": note}\n",
    "        ],\n",
    "        response_format=label_format,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    raw_content = structured_output['choices'][0]['message']['content']\n",
    "\n",
    "    # extract first JSON object to avoid JSONDecodeError\n",
    "    match = re.search(r\"\\{.*\\}\", raw_content, re.DOTALL)\n",
    "    if match:\n",
    "        label = json.loads(match.group())\n",
    "    else:\n",
    "        # fallback if JSON not found\n",
    "        label = {\n",
    "            \"imatinib_mentioned\": False,\n",
    "            \"related_drugs_mentioned\": False,\n",
    "            \"cml_diagnosed\": False,\n",
    "            \"cml_in_regression\": False\n",
    "        }\n",
    "\n",
    "    labelled_notes.append({\n",
    "        \"original_note\": note,\n",
    "        \"imatinib_mentioned\": label[\"imatinib_mentioned\"],\n",
    "        \"related_drugs_mentioned\": label[\"related_drugs_mentioned\"],\n",
    "        \"cml_diagnosed\": label[\"cml_diagnosed\"],\n",
    "        \"cml_in_regression\": label[\"cml_in_regression\"],\n",
    "    })\n",
    "\n",
    "    # status update every 10 notes\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processed {i} / {len(sample_notes)} notes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c636cbf5-08fb-4002-934a-01248464c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"open_hermes_test.json\", \"w\") as f:\n",
    "    json.dump(labelled_notes, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844bd4c-8ed4-4c9f-8153-9e1df4837b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb5d7a-57f3-4c0c-909d-8620f02af546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e91a2-8c91-4ad3-a39e-d77e1ab54473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed48736-2b30-4f8e-90f3-991c607d2ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcaaa0b-8373-4f54-b2ed-dc1f8a3ae71e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_tools",
   "language": "python",
   "name": "llm_tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
